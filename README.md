# An instrument for your filesystem

Carrier Bag will eat up a filesystem and find any image, video, audio, 3d model, or html file, and add it to a library that can be accessed through random or programmatic interfaces. 

The hierarchical file browser as the near sole method of navigating my media files makes me want to cry. I initially built Carrier Bag to serendipitously navigate the hundreds of media files from the export of over 30 virtual worlds I created on [New Art City](https://newart.city) between 2020 and 2022. It uses [Hydra Video Synth](https://github.com/hydra-synth/hydra) to blend and modulate media sources, with some features for dynamic patch loading.  

Over time, the tool has become something like an operating system for my art practice. I use it instead to give artists talks, author generative films, perform poems, and manage hardware installations of my archives. It currently supports keyboard, MIDI, OSC, and speech input, and also has an automated kiosk mode. 

I built the first version, now published as [*Free Computer*](https://github.com/miss-sammie/FREE-COMPUTER) in Summer 2024 during a residency in the 0xSalon at Trust.support. This is a vulnerable codebase— between lines 1000 and 2000 of my one giant JS file, you can see me start to understand how classes work. 

In January 2025 my parent’s house burned down with most of my possessions inside. Instead of going to therapy, I did an artist residency at [Dublab](https://www.dublab.com/events/112043/dublab-presents-severity-of-belonging-o) with Nina Keith and built this present version of Carrier Bag. I used it to create an archival water synthesizer which communicated with Nina Keith’s *Periphone,* a posthumous water avatar. We sourced a collection of 500 images and videos of water from community members, and blended them together in real time with audio input from *Periphone*. 

I imagine this iteration as one of many potential interfaces of for creatively and serendipitously navigating large collections of media. My goal for the next iteration is a modular complex of interfaces and viewer components, and with the ability to tag and append metadata to any readable file. I am also interested in more relational hypertext style authoring, and other document formats besides the current video synthesizer.


